{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copycat_CNN_Attack.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGs2p5qlCDv9",
        "colab_type": "code",
        "outputId": "34605db1-c744-4c60-e739-175d83d1b887",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!git clone https://github.com/tensorflow/cleverhans.git\n",
        "!pip install cleverhans/\n",
        "!pip install adversarial-robustness-toolbox"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Cloning into 'cleverhans'...\n",
            "remote: Enumerating objects: 13501, done.\u001b[K\n",
            "remote: Total 13501 (delta 0), reused 0 (delta 0), pack-reused 13501\u001b[K\n",
            "Receiving objects: 100% (13501/13501), 8.40 MiB | 24.52 MiB/s, done.\n",
            "Resolving deltas: 100% (9494/9494), done.\n",
            "Processing ./cleverhans\n",
            "Collecting nose\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 2.7MB/s \n",
            "\u001b[?25hCollecting pycodestyle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/0c/04a353e104d2f324f8ee5f4b32012618c1c86dd79e52a433b64fceed511b/pycodestyle-2.5.0-py2.py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (3.2.1)\n",
            "Collecting mnist~=0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/c4/5db3bfe009f8d71f1d532bbadbd0ec203764bba3a469e4703a889db8e5e0/mnist-0.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (1.18.3)\n",
            "Requirement already satisfied: tensorflow-probability in /tensorflow-1.15.2/python3.6 (from cleverhans==3.0.1) (0.7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (0.14.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (2.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans==3.0.1) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans==3.0.1) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans==3.0.1) (1.12.0)\n",
            "Building wheels for collected packages: cleverhans\n",
            "  Building wheel for cleverhans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cleverhans: filename=cleverhans-3.0.1-cp36-none-any.whl size=253453 sha256=985d49aa08c510a114d1d433d6b5ce558dd52719e1f89873a133347257be3645\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1kqlv4k8/wheels/d1/6b/1d/5cf7b3ca4c0cfc7f845628b8ed46366ab5f4f56b5483e9db7f\n",
            "Successfully built cleverhans\n",
            "Installing collected packages: nose, pycodestyle, mnist, cleverhans\n",
            "Successfully installed cleverhans-3.0.1 mnist-0.2.2 nose-1.3.7 pycodestyle-2.5.0\n",
            "Collecting adversarial-robustness-toolbox\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/b5/7c7ef44bd2729140930612b4d10af2dbcfa0ca6c9592251c490100b4753a/adversarial_robustness_toolbox-1.2.0-py3-none-any.whl (486kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.18.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.12.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (3.2.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (46.1.3)\n",
            "Collecting scikit-learn==0.22.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/48/e9fa9e252abcd1447eff6f9257636af31758a6e46fd5ce5d3c879f6907cb/scikit_learn-0.22.1-cp36-cp36m-manylinux1_x86_64.whl (7.0MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 46.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow==7.0.0 in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (7.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (0.10.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.22.1->adversarial-robustness-toolbox) (0.14.1)\n",
            "Installing collected packages: scikit-learn, adversarial-robustness-toolbox\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed adversarial-robustness-toolbox-1.2.0 scikit-learn-0.22.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4hGhLTdEWFs",
        "colab_type": "code",
        "outputId": "58bf9a15-5001-454d-e11d-13e934dd96fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "  \n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from art.attacks import FastGradientMethod\n",
        "from art.classifiers import KerasClassifier\n",
        "from art.utils import load_dataset\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "#  Load the CIFAR 10 dataset\n",
        "(x_train, y_train), (x_test, y_test), min_, max_ = load_dataset(str(\"cifar10\")) # Original Dataset\n",
        "print(\"x_train shape: \" + str(x_train.shape) + \"\\n\" + \"x_train size: \" + str(x_train.size) + \"\\n\" +\n",
        "      \"y_train shape: \" + str(y_train.shape) + \"\\n\" + \"y_train size: \" + str(y_train.size) + \"\\n\" +\n",
        "      \"x_test shape: \" + str(x_test.shape) + \"\\n\" + \"x_test size: \" + str(x_test.size) + \"\\n\" +\n",
        "      \"y_test shape: \" + str(y_test.shape) + \"\\n\" + \"y_test size: \" + str(y_test.size) + \"\\n\")\n",
        "\n",
        "#  Load the victim model\n",
        "hub_url = \"https://tfhub.dev/deepmind/ganeval-cifar10-convnet/1\"\n",
        "embed = hub.KerasLayer(hub_url, input_shape=(32,32,3) )\n",
        "model = tf.keras.Sequential([\n",
        "    embed,\n",
        "    tf.keras.layers.Activation( 'softmax' )\n",
        "])\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "victim_classifier = KerasClassifier(model=model, clip_values=(0., 1.))\n",
        "\n",
        "#Evaluate the victim model on the benign dataset\n",
        "predictions = victim_classifier.predict(x_test) # giving the classifier the x_test of the CIFAR-10 dataset.\n",
        "accuracy_benign = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test) # calculates the accuracy of the predictions\n",
        "print(\"Accuracy on original examples for victim classifier: {}%\\n\".format(accuracy_benign * 100))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "x_train size: 153600000\n",
            "y_train shape: (50000, 10)\n",
            "y_train size: 500000\n",
            "x_test shape: (10000, 32, 32, 3)\n",
            "x_test size: 30720000\n",
            "y_test shape: (10000, 10)\n",
            "y_test size: 100000\n",
            "\n",
            "WARNING:tensorflow:Entity <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7f30803e4b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7f30803e4b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7f30803e4b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer_1 (KerasLayer)   (None, 10)                7796426   \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 7,796,426\n",
            "Trainable params: 0\n",
            "Non-trainable params: 7,796,426\n",
            "_________________________________________________________________\n",
            "Accuracy on original examples for victim classifier: 94.52000000000001%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHjAkekleJ-O",
        "colab_type": "code",
        "outputId": "b9182df3-28a5-4c98-afc5-918b118968ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "    # Sampled dataset to train model\n",
        "x_train, y_train = x_train[:5000], y_train[:5000] # take 5000 samples for the training set\n",
        "print(\"x_train shape: \" + str(x_train.shape) + \"\\n\" + \"x_train size: \" + str(x_train.size) + \"\\n\" +\n",
        "      \"y_train shape: \" + str(y_train.shape) + \"\\n\" + \"y_train size: \" + str(y_train.size) + \"\\n\" +\n",
        "      \"x_test shape: \" + str(x_test.shape) + \"\\n\" + \"x_test size: \" + str(x_test.size) + \"\\n\" +\n",
        "      \"y_test shape: \" + str(y_test.shape) + \"\\n\" + \"y_test size: \" + str(y_test.size) + \"\\n\")\n",
        "\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=x_train.shape[1:]))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "#Create the classifier\n",
        "copycat_classifier = KerasClassifier(model=model, clip_values=(min_, max_))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (5000, 32, 32, 3)\n",
            "x_train size: 15360000\n",
            "y_train shape: (5000, 10)\n",
            "y_train size: 50000\n",
            "x_test shape: (10000, 32, 32, 3)\n",
            "x_test size: 30720000\n",
            "y_test shape: (10000, 10)\n",
            "y_test size: 100000\n",
            "\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,250,858\n",
            "Trainable params: 1,250,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkZA2qvuFNoC",
        "colab_type": "code",
        "outputId": "b7a54f37-fcfa-4f5e-fbff-4dd13bf5b6a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "from art.attacks import CopycatCNN\n",
        "extraction_attack = CopycatCNN(classifier=victim_classifier, batch_size_fit=128, batch_size_query=128, nb_epochs=10, nb_stolen=1000000) \n",
        "stolen_classifier = extraction_attack.extract(x=x_train, thieved_classifier=copycat_classifier)\n",
        "# Step 4: Evaluate the ART classifier on benign test examples\n",
        "predictions = stolen_classifier.predict(x_test)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
        "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:art.attacks.extraction.copycat_cnn:The size of the source input is smaller than the expected number of queries submitted to the victim classifier.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "39/39 [==============================] - 25s 638ms/step - loss: 0.3060 - accuracy: 0.8997\n",
            "Epoch 2/10\n",
            "39/39 [==============================] - 22s 559ms/step - loss: 0.2675 - accuracy: 0.9018\n",
            "Epoch 3/10\n",
            "39/39 [==============================] - 22s 556ms/step - loss: 0.2499 - accuracy: 0.9053\n",
            "Epoch 4/10\n",
            "39/39 [==============================] - 22s 555ms/step - loss: 0.2338 - accuracy: 0.9102\n",
            "Epoch 5/10\n",
            "39/39 [==============================] - 22s 556ms/step - loss: 0.2217 - accuracy: 0.9133\n",
            "Epoch 6/10\n",
            "39/39 [==============================] - 22s 557ms/step - loss: 0.2122 - accuracy: 0.9153\n",
            "Epoch 7/10\n",
            "39/39 [==============================] - 22s 556ms/step - loss: 0.2015 - accuracy: 0.9211\n",
            "Epoch 8/10\n",
            "39/39 [==============================] - 22s 556ms/step - loss: 0.1956 - accuracy: 0.9227\n",
            "Epoch 9/10\n",
            "39/39 [==============================] - 22s 558ms/step - loss: 0.1867 - accuracy: 0.9260\n",
            "Epoch 10/10\n",
            "39/39 [==============================] - 22s 555ms/step - loss: 0.1756 - accuracy: 0.9305\n",
            "Accuracy on benign test examples: 54.779999999999994%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHXkWvogUqZG",
        "colab_type": "code",
        "outputId": "4b4c8bd9-09be-4377-c96f-454d62f71c68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "extraction_attack = CopycatCNN(classifier=victim_classifier, batch_size_fit=128, batch_size_query=128, nb_epochs=10, nb_stolen=1000000) \n",
        "stolen_classifier = extraction_attack.extract(x=x_train[:5000], thieved_classifier=copycat_classifier)\n",
        "#  Evaluate the ART classifier on benign test examples\n",
        "predictions = stolen_classifier.predict(x_test)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
        "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:art.attacks.extraction.copycat_cnn:The size of the source input is smaller than the expected number of queries submitted to the victim classifier.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "39/39 [==============================] - 20s 522ms/step - loss: 1.4165 - accuracy: 0.4960\n",
            "Epoch 2/10\n",
            "39/39 [==============================] - 20s 522ms/step - loss: 1.3136 - accuracy: 0.5260\n",
            "Epoch 3/10\n",
            "39/39 [==============================] - 20s 523ms/step - loss: 1.2367 - accuracy: 0.5599\n",
            "Epoch 4/10\n",
            "39/39 [==============================] - 20s 521ms/step - loss: 1.1681 - accuracy: 0.5793\n",
            "Epoch 5/10\n",
            "39/39 [==============================] - 20s 525ms/step - loss: 1.0765 - accuracy: 0.6194\n",
            "Epoch 6/10\n",
            "39/39 [==============================] - 20s 521ms/step - loss: 1.0258 - accuracy: 0.6362\n",
            "Epoch 7/10\n",
            "39/39 [==============================] - 20s 523ms/step - loss: 0.9591 - accuracy: 0.6591\n",
            "Epoch 8/10\n",
            "39/39 [==============================] - 20s 522ms/step - loss: 0.8917 - accuracy: 0.6813\n",
            "Epoch 9/10\n",
            "39/39 [==============================] - 20s 524ms/step - loss: 0.8365 - accuracy: 0.7053\n",
            "Epoch 10/10\n",
            "39/39 [==============================] - 20s 523ms/step - loss: 0.7843 - accuracy: 0.7290\n",
            "Accuracy on benign test examples: 56.599999999999994%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdpinueJCsZA",
        "colab_type": "code",
        "outputId": "0055a34c-3616-468e-ea70-46b38ffff4b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "extraction_attack = CopycatCNN(classifier=victim_classifier, batch_size_fit=128, batch_size_query=128, nb_epochs=10, nb_stolen=1000000) \n",
        "stolen_classifier = extraction_attack.extract(x=x_train[:15000], thieved_classifier=copycat_classifier)\n",
        "#  Evaluate the ART classifier on benign test examples\n",
        "predictions = stolen_classifier.predict(x_test)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
        "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:art.attacks.extraction.copycat_cnn:The size of the source input is smaller than the expected number of queries submitted to the victim classifier.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "39/39 [==============================] - 20s 522ms/step - loss: 0.7196 - accuracy: 0.7484\n",
            "Epoch 2/10\n",
            "39/39 [==============================] - 20s 523ms/step - loss: 0.6598 - accuracy: 0.7780\n",
            "Epoch 3/10\n",
            "39/39 [==============================] - 20s 522ms/step - loss: 0.6033 - accuracy: 0.7937\n",
            "Epoch 4/10\n",
            "39/39 [==============================] - 20s 522ms/step - loss: 0.5743 - accuracy: 0.8063\n",
            "Epoch 5/10\n",
            "39/39 [==============================] - 20s 522ms/step - loss: 0.5090 - accuracy: 0.8269\n",
            "Epoch 6/10\n",
            "39/39 [==============================] - 20s 522ms/step - loss: 0.4823 - accuracy: 0.8379\n",
            "Epoch 7/10\n",
            "39/39 [==============================] - 20s 521ms/step - loss: 0.4495 - accuracy: 0.8442\n",
            "Epoch 8/10\n",
            "39/39 [==============================] - 20s 525ms/step - loss: 0.4058 - accuracy: 0.8582\n",
            "Epoch 9/10\n",
            "39/39 [==============================] - 20s 522ms/step - loss: 0.3650 - accuracy: 0.8736\n",
            "Epoch 10/10\n",
            "39/39 [==============================] - 20s 520ms/step - loss: 0.3321 - accuracy: 0.8860\n",
            "Accuracy on benign test examples: 59.14%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quh31QMiWUCC",
        "colab_type": "code",
        "outputId": "acc73392-29fb-4376-d468-880abc3712ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "extraction_attack = CopycatCNN(classifier=victim_classifier, batch_size_fit=128, batch_size_query=128, nb_epochs=10, nb_stolen=2500) \n",
        "stolen_classifier = extraction_attack.extract(x=x_train[:2500], thieved_classifier=copycat_classifier)\n",
        "#  Evaluate the ART classifier on benign test examples\n",
        "predictions = stolen_classifier.predict(x_test)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
        "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "19/19 [==============================] - 10s 523ms/step - loss: 0.3065 - accuracy: 0.8890\n",
            "Epoch 2/10\n",
            "19/19 [==============================] - 10s 524ms/step - loss: 0.2792 - accuracy: 0.9025\n",
            "Epoch 3/10\n",
            "19/19 [==============================] - 10s 524ms/step - loss: 0.2309 - accuracy: 0.9215\n",
            "Epoch 4/10\n",
            "19/19 [==============================] - 10s 526ms/step - loss: 0.2246 - accuracy: 0.9264\n",
            "Epoch 5/10\n",
            "19/19 [==============================] - 10s 522ms/step - loss: 0.1960 - accuracy: 0.9387\n",
            "Epoch 6/10\n",
            "19/19 [==============================] - 10s 523ms/step - loss: 0.1780 - accuracy: 0.9416\n",
            "Epoch 7/10\n",
            "19/19 [==============================] - 10s 522ms/step - loss: 0.1736 - accuracy: 0.9428\n",
            "Epoch 8/10\n",
            "19/19 [==============================] - 10s 525ms/step - loss: 0.1684 - accuracy: 0.9449\n",
            "Epoch 9/10\n",
            "19/19 [==============================] - 10s 525ms/step - loss: 0.1462 - accuracy: 0.9494\n",
            "Epoch 10/10\n",
            "19/19 [==============================] - 10s 525ms/step - loss: 0.1626 - accuracy: 0.9449\n",
            "Accuracy on benign test examples: 57.989999999999995%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8razmbV4WZd7",
        "colab_type": "code",
        "outputId": "65eb25ae-b9f4-43f4-d8fd-917019e6ce2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "extraction_attack = CopycatCNN(classifier=victim_classifier, batch_size_fit=128, batch_size_query=128, nb_epochs=10, nb_stolen=5000) \n",
        "stolen_classifier = extraction_attack.extract(x=x_train[:5000], thieved_classifier=copycat_classifier)\n",
        "# Evaluate the ART classifier on benign test examples\n",
        "predictions = stolen_classifier.predict(x_test)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
        "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "39/39 [==============================] - 20s 521ms/step - loss: 0.3186 - accuracy: 0.8924\n",
            "Epoch 2/10\n",
            "39/39 [==============================] - 20s 522ms/step - loss: 0.2514 - accuracy: 0.9195\n",
            "Epoch 3/10\n",
            "39/39 [==============================] - 20s 520ms/step - loss: 0.2418 - accuracy: 0.9167\n",
            "Epoch 4/10\n",
            "39/39 [==============================] - 20s 526ms/step - loss: 0.2235 - accuracy: 0.9215\n",
            "Epoch 5/10\n",
            "39/39 [==============================] - 20s 520ms/step - loss: 0.2187 - accuracy: 0.9267\n",
            "Epoch 6/10\n",
            "39/39 [==============================] - 20s 522ms/step - loss: 0.1853 - accuracy: 0.9375\n",
            "Epoch 7/10\n",
            "39/39 [==============================] - 20s 520ms/step - loss: 0.1830 - accuracy: 0.9409\n",
            "Epoch 8/10\n",
            "39/39 [==============================] - 20s 520ms/step - loss: 0.1924 - accuracy: 0.9299\n",
            "Epoch 9/10\n",
            "39/39 [==============================] - 20s 522ms/step - loss: 0.1847 - accuracy: 0.9355\n",
            "Epoch 10/10\n",
            "39/39 [==============================] - 20s 522ms/step - loss: 0.1547 - accuracy: 0.9469\n",
            "Accuracy on benign test examples: 60.11%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDuOindVWbvc",
        "colab_type": "code",
        "outputId": "e8a2763e-dd9f-4228-c1d1-cd7648c4502c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "extraction_attack = CopycatCNN(classifier=victim_classifier, batch_size_fit=128, batch_size_query=128, nb_epochs=10, nb_stolen=15000) \n",
        "stolen_classifier = extraction_attack.extract(x=x_train[:15000], thieved_classifier=copycat_classifier)\n",
        "#  Evaluate the ART classifier on benign test examples\n",
        "predictions = stolen_classifier.predict(x_test)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
        "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:art.attacks.extraction.copycat_cnn:The size of the source input is smaller than the expected number of queries submitted to the victim classifier.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "39/39 [==============================] - 20s 520ms/step - loss: 0.1778 - accuracy: 0.9411\n",
            "Epoch 2/10\n",
            "39/39 [==============================] - 20s 519ms/step - loss: 0.1602 - accuracy: 0.9465\n",
            "Epoch 3/10\n",
            "39/39 [==============================] - 20s 522ms/step - loss: 0.1546 - accuracy: 0.9513\n",
            "Epoch 4/10\n",
            "39/39 [==============================] - 20s 521ms/step - loss: 0.1398 - accuracy: 0.9541\n",
            "Epoch 5/10\n",
            "39/39 [==============================] - 20s 521ms/step - loss: 0.1400 - accuracy: 0.9559\n",
            "Epoch 6/10\n",
            "39/39 [==============================] - 20s 521ms/step - loss: 0.1246 - accuracy: 0.9595\n",
            "Epoch 7/10\n",
            "39/39 [==============================] - 21s 526ms/step - loss: 0.1295 - accuracy: 0.9539\n",
            "Epoch 8/10\n",
            "39/39 [==============================] - 20s 519ms/step - loss: 0.1207 - accuracy: 0.9625\n",
            "Epoch 9/10\n",
            "39/39 [==============================] - 20s 521ms/step - loss: 0.1150 - accuracy: 0.9603\n",
            "Epoch 10/10\n",
            "39/39 [==============================] - 21s 530ms/step - loss: 0.1137 - accuracy: 0.9653\n",
            "Accuracy on benign test examples: 60.19%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}