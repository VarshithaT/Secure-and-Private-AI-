{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AttackTransferability.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQ2PmsY283WU",
        "colab_type": "code",
        "outputId": "5b778f13-0b6f-4e2e-e1cc-27f29f86f49f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 892
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "#!git clone https://github.com/tensorflow/cleverhans.git\n",
        "!pip install cleverhans\n",
        "!pip install adversarial-robustness-toolbox"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Collecting cleverhans\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/a0/f0b4386b719f343c4ed3e13cd7792a7a7a4674566ca9b2b34a09b7424220/cleverhans-3.0.1-py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 2.8MB/s \n",
            "\u001b[?25hCollecting mnist~=0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/c4/5db3bfe009f8d71f1d532bbadbd0ec203764bba3a469e4703a889db8e5e0/mnist-0.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tensorflow-probability in /tensorflow-1.15.2/python3.6 (from cleverhans) (0.7.0)\n",
            "Collecting pycodestyle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/0c/04a353e104d2f324f8ee5f4b32012618c1c86dd79e52a433b64fceed511b/pycodestyle-2.5.0-py2.py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.18.3)\n",
            "Collecting nose\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 59.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (3.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.12.0)\n",
            "Requirement already satisfied: cloudpickle>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.3.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (4.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (1.2.0)\n",
            "Installing collected packages: mnist, pycodestyle, nose, cleverhans\n",
            "Successfully installed cleverhans-3.0.1 mnist-0.2.2 nose-1.3.7 pycodestyle-2.5.0\n",
            "Collecting adversarial-robustness-toolbox\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/b5/7c7ef44bd2729140930612b4d10af2dbcfa0ca6c9592251c490100b4753a/adversarial_robustness_toolbox-1.2.0-py3-none-any.whl (486kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (46.1.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.12.0)\n",
            "Collecting scikit-learn==0.22.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/48/e9fa9e252abcd1447eff6f9257636af31758a6e46fd5ce5d3c879f6907cb/scikit_learn-0.22.1-cp36-cp36m-manylinux1_x86_64.whl (7.0MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 13.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (3.2.1)\n",
            "Requirement already satisfied: Pillow==7.0.0 in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.18.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.22.1->adversarial-robustness-toolbox) (0.14.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (0.10.0)\n",
            "Installing collected packages: scikit-learn, adversarial-robustness-toolbox\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed adversarial-robustness-toolbox-1.2.0 scikit-learn-0.22.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DrTwTGfBazl",
        "colab_type": "code",
        "outputId": "d6ce5118-8b3a-4a33-c0d9-84421099f760",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from art.classifiers import KerasClassifier\n",
        "from art.utils import load_dataset\n",
        "import random\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout, BatchNormalization\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "from cleverhans.compat import softmax_cross_entropy_with_logits\n",
        "from cleverhans.utils_keras import KerasModelWrapper\n",
        "\n",
        "\n",
        "\n",
        "# Load the CIFAR-10 Dataset\n",
        "(x_train_victim, y_train_victim), (x_test_victim, y_test_victim), min_, max_ = load_dataset(str(\"cifar10\")) # Original Dataset\n",
        "print(\"x_train_victim shape: \" + str(x_train_victim.shape) + \"\\n\" + \"x_train_victim size: \" + str(x_train_victim.size) + \"\\n\" + # this print statement is used for understanding what the CIFAR-10 dataset is\n",
        "      \"y_train_victim shape: \" + str(y_train_victim.shape) + \"\\n\" + \"y_train_victim size: \" + str(y_train_victim.size) + \"\\n\" +\n",
        "      \"x_test_victim shape: \" + str(x_test_victim.shape) + \"\\n\" + \"x_test_victim size: \" + str(x_test_victim.size) + \"\\n\" +\n",
        "      \"y_test_victim shape: \" + str(y_test_victim.shape) + \"\\n\" + \"y_test_victim size: \" + str(y_test_victim.size) + \"\\n\")\n",
        "print()\n",
        "\n",
        "\n",
        "#  Load the victim model\n",
        "classifier_url =\"https://tfhub.dev/deepmind/ganeval-cifar10-convnet/1\" #@param {type:\"string\"} # model is downloaded from this site\n",
        "IMAGE_SHAPE = (32, 32) # the image shape is needed so that the model knows the input-shape and since we are working with the CIFAR-10 all the images are 32 x 32 color images\n",
        "victim_classifier = KerasClassifier(model=tf.keras.Sequential([hub.KerasLayer(classifier_url, input_shape=IMAGE_SHAPE+(3,))]), clip_values=(min_, max_)) # this bascially creates a keras wrapper around the downloaded model so that we can use it with keras functions.\n",
        "\n",
        "\n",
        "# Evaluating the victim model on the benign dataset\n",
        "predictions = victim_classifier.predict(x_test_victim) # giving the classifier the x_test of the CIFAR-10 dataset.\n",
        "accuracy_benign = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test_victim, axis=1)) / len(y_test_victim) # calculates the accuracy of the predictions\n",
        "print(\"Accuracy on benign test examples for victim classifier: {}%\\n\".format(accuracy_benign * 100))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/cleverhans/utils_tf.py:341: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "x_train_victim shape: (50000, 32, 32, 3)\n",
            "x_train_victim size: 153600000\n",
            "y_train_victim shape: (50000, 10)\n",
            "y_train_victim size: 500000\n",
            "x_test_victim shape: (10000, 32, 32, 3)\n",
            "x_test_victim size: 30720000\n",
            "y_test_victim shape: (10000, 10)\n",
            "y_test_victim size: 100000\n",
            "\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7f063dc437f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7f063dc437f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:art.classifiers.keras:Keras model has no loss set. Classifier tries to use `k.sparse_categorical_crossentropy`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7f063dc437f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on benign test examples for victim classifier: 94.52000000000001%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmkSM0g_GHyE",
        "colab_type": "code",
        "outputId": "09976622-503f-437e-bbd0-81bb2193f3ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "#  Collect subset\n",
        "def exract_subset(data, labels):\n",
        "    x_pre = []  \n",
        "    y_pre = []  \n",
        "    #count = 0\n",
        "    for index in range(0, len(data)):  \n",
        "        x_pre.append(data[index])  \n",
        "        y_predict = np.argmax(victim_classifier.predict( data[index].reshape( (1, data[index].shape[ 0 ], data[index].shape[ 1 ], data[index].shape[ 2 ]) ) ) )  # add the image label to the y_test set\n",
        "        y_pre.append(y_predict)\n",
        "       \n",
        "    x = np.asarray(x_pre)  \n",
        "    y = keras.utils.to_categorical(np.asarray(y_pre), 10)  \n",
        "    return x, y\n",
        "\n",
        "X_subset, Y_subset = exract_subset( x_test_victim, y_test_victim )\n",
        "print(\"X_subset shape: \" + str(X_subset.shape) + \"\\n\" + \"X_subset size: \" + str(X_subset.size) + \"\\n\" +\n",
        "      \"Y_subset shape: \" + str(Y_subset.shape) + \"\\n\" + \"Y_subset size: \" + str(Y_subset.size) + \"\\n\")\n",
        "\n",
        "np.save('/content/gdrive/My Drive/X_subset', X_subset) \n",
        "np.save('/content/gdrive/My Drive/Y_subset', Y_subset) "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_subset shape: (10000, 32, 32, 3)\n",
            "X_subset size: 30720000\n",
            "Y_subset shape: (10000, 10)\n",
            "Y_subset size: 100000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1NU-2c6zJvj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JIOGhCmrBac",
        "colab_type": "text"
      },
      "source": [
        "Up to this point the victim classifer has been evaluted on the test set of cifar10 = 94.5% accuracy, and the test set has been extracted with the labels given by the victim model's predtiction, i.e. 10000 examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hdaJHUsLVrM",
        "colab_type": "code",
        "outputId": "ac06a7e8-8c40-4dd5-eca7-87dca4ca88a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "#  Loading the subset data\n",
        "X = np.load('/content/gdrive/My Drive/X_subset.npy') \n",
        "Y = np.load('/content/gdrive/My Drive/Y_subset.npy') \n",
        "print(\"X shape: \" + str(X.shape) + \"\\n\" + \"X size: \" + str(X.size) + \"\\n\" + \n",
        "      \"Y shape: \" + str(Y.shape) + \"\\n\" + \"Y size: \" + str(Y.size) + \"\\n\")\n",
        "print()\n",
        "\n",
        "x_train_substitute = X[:7500]\n",
        "y_train_substitute = Y[:7500]\n",
        "print(\"x_train_substitute shape: \" + str(x_train_substitute.shape) + \"\\n\" + \"x_train_substitute size: \" + str(x_train_substitute.size) + \"\\n\" + \n",
        "      \"y_train_substitute shape: \" + str(y_train_substitute.shape) + \"\\n\" + \"y_train_substitute size: \" + str(y_train_substitute.size) + \"\\n\")\n",
        "print()\n",
        "\n",
        "x_test_substitute = X[7500:]\n",
        "y_test_substitute = Y[7500:]\n",
        "print(\"x_test_substitute shape: \" + str(x_test_substitute.shape) + \"\\n\" + \"x_test_substitute size: \" + str(x_test_substitute.size) + \"\\n\" + \n",
        "      \"y_test_substitute shape: \" + str(y_test_substitute.shape) + \"\\n\" + \"y_test_substitute size: \" + str(y_test_substitute.size) + \"\\n\")\n",
        "print()\n",
        "\n",
        "\n",
        "#  Creating the model\n",
        "model_substitute = Sequential()\n",
        "model_substitute.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=x_train_substitute.shape[1:]))\n",
        "model_substitute.add(Activation(\"relu\"))\n",
        "model_substitute.add(Conv2D(32, (3, 3)))\n",
        "model_substitute.add(Activation(\"relu\"))\n",
        "model_substitute.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_substitute.add(Dropout(0.25))\n",
        "\n",
        "model_substitute.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model_substitute.add(Activation(\"relu\"))\n",
        "model_substitute.add(Conv2D(64, (3, 3)))\n",
        "model_substitute.add(Activation(\"relu\"))\n",
        "model_substitute.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_substitute.add(Dropout(0.25))\n",
        "\n",
        "model_substitute.add(Flatten())\n",
        "model_substitute.add(Dense(512))\n",
        "model_substitute.add(Activation(\"relu\"))\n",
        "model_substitute.add(Dropout(0.5))\n",
        "model_substitute.add(Dense(10))\n",
        "model_substitute.add(Activation(\"softmax\"))\n",
        "\n",
        "model_substitute.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "\n",
        "# Step 3: Creating the classifier\n",
        "substitute_classifier = KerasClassifier(model=model_substitute, clip_values=(0., 1.))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape: (10000, 32, 32, 3)\n",
            "X size: 30720000\n",
            "Y shape: (10000, 10)\n",
            "Y size: 100000\n",
            "\n",
            "\n",
            "x_train_substitute shape: (7500, 32, 32, 3)\n",
            "x_train_substitute size: 23040000\n",
            "y_train_substitute shape: (7500, 10)\n",
            "y_train_substitute size: 75000\n",
            "\n",
            "\n",
            "x_test_substitute shape: (2500, 32, 32, 3)\n",
            "x_test_substitute size: 7680000\n",
            "y_test_substitute shape: (2500, 10)\n",
            "y_test_substitute size: 25000\n",
            "\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3JDApld2YoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKGkIK_V2Ywh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkNLPh19LVyV",
        "colab_type": "code",
        "outputId": "661076aa-5544-44fd-fdf0-877a01b8dc06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        }
      },
      "source": [
        "def one_hot(value):\n",
        "  vec = np.zeros((10))\n",
        "  vec[value] = 1\n",
        "  return vec\n",
        "\n",
        "def jacobian(predictions, inputs, num_classes):\n",
        "    #That is, how does the kth element of yhat vary wrt x?\n",
        "    return [tf.gradients(predictions[:, c], inputs)[0] for c in range(0, num_classes)]\n",
        "\n",
        "def jacobian_prediction_dimension(grads, predictions):\n",
        "    return [grads[predictions[i]][i] for i in np.arange(len(predictions))]\n",
        "\n",
        "wrapper = KerasModelWrapper( model_substitute ) # create keras wrapper for substitute model\n",
        "adv_train_epochs = 1 # run the loop for 2 runs genreating 22500 samples from 7500 samples\n",
        "adv_train_set = x_train_substitute / 255.0 # assign the varaible adv_train_set the x_train which holds 7500 samples\n",
        "\n",
        "\n",
        "for adv_train_epoch in range(adv_train_epochs): # loop for syntehtic data generation\n",
        "    print(\"RUN: \" + str(adv_train_epoch))\n",
        "    print(\"Before: \")\n",
        "    print(adv_train_set.shape) # initial size of the x_train (7500, 32, 32, 3)\n",
        "\n",
        "    # Get labels from victim model and train substitute model\n",
        "    oracle_labels = victim_classifier.predict(adv_train_set) # have the victim model label the x_train values, i.e. getting the y_train labels = 7500 labels\n",
        "    print(\"Oracle Predict: \")\n",
        "    print(oracle_labels.shape) # shape of the y_train = (7500, 10)\n",
        "    substitute_classifier.fit(adv_train_set, oracle_labels, nb_epochs=10, batch_size=128) # fit the substitute model with the training set created thus far.    \n",
        "\n",
        "    # Convert the labels from victim model to one hot encoded vectors\n",
        "    oracle_labels = np.zeros((adv_train_set.shape[0],10))\n",
        "    for i in range(0,x_train_substitute.shape[0]):\n",
        "        oracle_labels[i] = one_hot(np.argmax(victim_classifier.predict( adv_train_set[i].reshape( (1, adv_train_set[i].shape[ 0 ], adv_train_set[i].shape[ 1 ], adv_train_set[i].shape[ 2 ]) ) )))\n",
        "    print(\"Inside Augment: \" + str(oracle_labels.shape))\n",
        "    \n",
        "    # Create a session\n",
        "    with tf.Session() as sess:\n",
        "        xm = model_substitute.layers[0].input \n",
        "        yhat = wrapper.get_logits( xm )\n",
        "        init = tf.global_variables_initializer()\n",
        "        sess = tf.Session( )   \n",
        "        sess.run(init) # Initializes the variables\n",
        "        grads = sess.run(jacobian(yhat, xm, 10), feed_dict={xm: adv_train_set}) # compute the grads with the jacobian function\n",
        "        jpd = jacobian_prediction_dimension(grads, np.argmax(oracle_labels, 1))\n",
        "\n",
        "    perturbed_set = []\n",
        "    jbda_lambda = 0.1\n",
        "    tau = 1\n",
        "    jbda_epoch_lambda = jbda_lambda * np.power(-1, np.floor(adv_train_epoch/tau))\n",
        "    for idx, example in enumerate(adv_train_set):\n",
        "        new_example = example + jbda_epoch_lambda * (np.sign(jpd[idx]))\n",
        "        perturbed_set.append(new_example)\n",
        "    adv_train_set = np.vstack((adv_train_set, np.array(perturbed_set)))\n",
        "\n",
        "    print(\"After: \")\n",
        "    print(adv_train_set.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RUN: 0\n",
            "Before: \n",
            "(7500, 32, 32, 3)\n",
            "Oracle Predict: \n",
            "(7500, 10)\n",
            "Epoch 1/10\n",
            "58/58 [==============================] - 18s 313ms/step - loss: -4761129.9512 - accuracy: 0.9725\n",
            "Epoch 2/10\n",
            "58/58 [==============================] - 18s 305ms/step - loss: -3389399433.6552 - accuracy: 0.9922\n",
            "Epoch 3/10\n",
            "58/58 [==============================] - 18s 305ms/step - loss: -153465665483.0345 - accuracy: 0.9900\n",
            "Epoch 4/10\n",
            "58/58 [==============================] - 18s 306ms/step - loss: -2017703191940.4136 - accuracy: 0.9915\n",
            "Epoch 5/10\n",
            "58/58 [==============================] - 18s 306ms/step - loss: -13460708939846.6211 - accuracy: 0.9926\n",
            "Epoch 6/10\n",
            "58/58 [==============================] - 18s 306ms/step - loss: -58916139578615.1719 - accuracy: 0.9923\n",
            "Epoch 7/10\n",
            "58/58 [==============================] - 18s 306ms/step - loss: -194983216590989.2500 - accuracy: 0.9911\n",
            "Epoch 8/10\n",
            "58/58 [==============================] - 18s 305ms/step - loss: -530468002061488.5625 - accuracy: 0.9926\n",
            "Epoch 9/10\n",
            "58/58 [==============================] - 18s 311ms/step - loss: -1247176017865198.2500 - accuracy: 0.9907\n",
            "Epoch 10/10\n",
            "58/58 [==============================] - 18s 306ms/step - loss: -2622122203256338.0000 - accuracy: 0.9916\n",
            "Inside Augment: (7500, 10)\n",
            "After: \n",
            "(15000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COWjZnOofiP8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0e142e93-72e2-426d-d3b9-eca1bfd5ec77"
      },
      "source": [
        "print(adv_train_set.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsCZtvT52ZVG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "397544b7-b546-4a1e-c4d1-1ba2fb11a4ee"
      },
      "source": [
        "# Collect subset\n",
        "def exract_subset(data):\n",
        "    x_pre = []  \n",
        "    y_pre = []  \n",
        "    #count = 0\n",
        "    for index in range(0, len(data)):  \n",
        "        x_pre.append(data[index])  \n",
        "        y_predict = np.argmax(victim_classifier.predict( data[index].reshape( (1, data[index].shape[ 0 ], data[index].shape[ 1 ], data[index].shape[ 2 ]) ) ) )  # add the image label to the y_test set\n",
        "        y_pre.append(y_predict)\n",
        "        #if y_predict != np.argmax(labels[index]):\n",
        "            #print(str(np.argmax(labels[index])) + \" : \" + str(y_predict))\n",
        "            #count = count + 1\n",
        "    #print(count)\n",
        "    x = np.asarray(x_pre)  \n",
        "    y = keras.utils.to_categorical(np.asarray(y_pre), 10)  \n",
        "    return x, y\n",
        "\n",
        "X_synthetic, Y_synthetic = exract_subset( adv_train_set )\n",
        "print(\"X_synthetic shape: \" + str(X_synthetic.shape) + \"\\n\" + \"X_synthetic size: \" + str(X_synthetic.size) + \"\\n\" +\n",
        "      \"Y_synthetic shape: \" + str(Y_synthetic.shape) + \"\\n\" + \"Y_synthetic size: \" + str(Y_synthetic.size) + \"\\n\")\n",
        "\n",
        "np.save('/content/gdrive/My Drive/X_synthetic', X_synthetic) \n",
        "np.save('/content/gdrive/My Drive/Y_synthetic', Y_synthetic) "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_synthetic shape: (15000, 32, 32, 3)\n",
            "X_synthetic size: 46080000\n",
            "Y_synthetic shape: (15000, 10)\n",
            "Y_synthetic size: 150000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfyT_wUmfq4K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "78d68d8b-c3ad-4ebd-b92f-9543b4564003"
      },
      "source": [
        "X_train = np.load('/content/gdrive/My Drive/X_synthetic.npy') \n",
        "Y_train = np.load('/content/gdrive/My Drive/Y_synthetic.npy') \n",
        "print(\"X shape: \" + str(X.shape) + \"\\n\" + \"X size: \" + str(X.size) + \"\\n\" + \n",
        "      \"Y shape: \" + str(Y.shape) + \"\\n\" + \"Y size: \" + str(Y.size) + \"\\n\")\n",
        "print()\n",
        "\n",
        "substitute_classifier.fit(X_train, Y_train, nb_epochs=10, batch_size=128)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape: (10000, 32, 32, 3)\n",
            "X size: 30720000\n",
            "Y shape: (10000, 10)\n",
            "Y size: 100000\n",
            "\n",
            "\n",
            "Epoch 1/10\n",
            "117/117 [==============================] - 40s 345ms/step - loss: 164265293071.3163 - accuracy: 0.7601\n",
            "Epoch 2/10\n",
            "117/117 [==============================] - 36s 304ms/step - loss: 99132766855.6581 - accuracy: 0.7075\n",
            "Epoch 3/10\n",
            "117/117 [==============================] - 36s 305ms/step - loss: 62989470168.6154 - accuracy: 0.7147\n",
            "Epoch 4/10\n",
            "117/117 [==============================] - 36s 305ms/step - loss: 66073176186.5299 - accuracy: 0.7055\n",
            "Epoch 5/10\n",
            "117/117 [==============================] - 36s 306ms/step - loss: 53688011784.7521 - accuracy: 0.7092\n",
            "Epoch 6/10\n",
            "117/117 [==============================] - 36s 305ms/step - loss: 67378633281.6410 - accuracy: 0.7136\n",
            "Epoch 7/10\n",
            "117/117 [==============================] - 36s 306ms/step - loss: 27039552363.2137 - accuracy: 0.7087\n",
            "Epoch 8/10\n",
            "117/117 [==============================] - 37s 314ms/step - loss: 18308743010.4615 - accuracy: 0.6948\n",
            "Epoch 9/10\n",
            "117/117 [==============================] - 36s 305ms/step - loss: 1944136548.7863 - accuracy: 0.6850\n",
            "Epoch 10/10\n",
            "117/117 [==============================] - 36s 305ms/step - loss: 146874560.1795 - accuracy: 0.6537\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHHU1w5i2ZZ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "19071378-3503-44f5-f7ba-de606a721cd0"
      },
      "source": [
        "#Evaluate the ART classifier on benign test examples\n",
        "predictions = substitute_classifier.predict(x_test_substitute)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test_substitute, axis=1)) / len(y_test_substitute)\n",
        "print(\"Accuracy on benign test examples for substitute classifier: {}%\".format(accuracy * 100))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on benign test examples for substitute classifier: 10.639999999999999%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GXsltyL2aA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "substitute_classifier.save(\"/content/gdrive/My Drive/Attack_Transfer_Substitute_Classifier_V3.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvEjpFHCtqVl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "2047ab53-5d98-4ba3-e587-b64d59fbee23"
      },
      "source": [
        "!pip install adversarial-robustness-toolbox"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: adversarial-robustness-toolbox in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.4.1)\n",
            "Requirement already satisfied: Pillow==7.0.0 in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (7.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (46.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.18.3)\n",
            "Requirement already satisfied: scikit-learn==0.22.1 in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (0.22.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (3.2.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.22.1->adversarial-robustness-toolbox) (0.14.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmNwHPC6uMUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import art\n",
        "from art.classifiers import KerasClassifier\n",
        "tf.compat.v1.disable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gv0poHGh2aHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from art.attacks import FastGradientMethod\n",
        "\n",
        "fgsm = FastGradientMethod(classifier=substitute_classifier)\n",
        "x_adversarial_fgsm = fgsm.generate(x_train_substitute,y_train_substitute)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlOXKgX5zAYf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3a4c8535-6a3d-450c-8d8f-ba5a8f201caa"
      },
      "source": [
        "predictions = substitute_classifier.predict(x_test_substitute)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test_substitute, axis=1)) / len(y_test_substitute)\n",
        "print(\"Accuracy on original examples for substitute classifier: {}%\".format(accuracy))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on original examples for substitute classifier: 0.1064%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBjeYvRquwfn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e4fab6fd-70ce-4fd4-ee75-97264ac38f6b"
      },
      "source": [
        "predictions = substitute_classifier.predict(x_adversarial_fgsm)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_train_substitute, axis=1)) / len(y_train_substitute)\n",
        "print(\"Accuracy on adversarial exales for substitute classifier:{}\".format(accuracy))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on adversarial exales for substitute classifier:0.09906666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEfS3Pygzpmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "victim_classifier = KerasClassifier(model=model_substitute, clip_values=(0., 1.))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGAnS3Pdzxdc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0e130b63-8b1c-4c19-9989-a0e3600302b3"
      },
      "source": [
        "predictions = victim_classifier.predict(x_adversarial_fgsm) # giving the classifier the x_test of the CIFAR-10 dataset.\n",
        "accuracy_benign = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_train_substitute, axis=1)) / len(y_train_substitute) # calculates the accuracy of the predictions\n",
        "print(\"Accuracy on benign test examples for victim classifier: {}%\\n\".format(accuracy_benign * 100))\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on benign test examples for victim classifier: 9.906666666666666%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6R-8WOW1tSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from art.attacks import SaliencyMapMethod\n",
        "\n",
        "sm = SaliencyMapMethod(classifier=substitute_classifier)\n",
        "x_adversarial_sm = fgsm.generate(x_train_substitute,y_train_substitute)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBXRrZf713xf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "265332f1-9c98-48cc-d2a8-839089c218ba"
      },
      "source": [
        "predictions = substitute_classifier.predict(x_adversarial_sm)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_train_substitute, axis=1)) / len(y_train_substitute)\n",
        "print(\"Accuracy on original examples for substitute classifier: {}%\".format(accuracy*100))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on original examples for substitute classifier: 9.906666666666666%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}